{"componentChunkName":"component---src-templates-blog-template-tsx","path":"/blog/fc131408b78fb50e8269/","result":{"data":{"markdownRemark":{"html":"<h3>\n<span id=\"背景\" class=\"fragment\"></span><a href=\"#%E8%83%8C%E6%99%AF\"><i class=\"fa fa-link\"></i></a>背景</h3>\n<hr>\n<p>Railsでsslを常に使ってて、ドメイン内で一部sslを適用したくないところがあり、<br><br>\nいろいろ検証してみました。<br><br>\nとりあえずsslを無効にしてアクセスしてみようとしたらハマった。  </p>\n<h3>\n<span id=\"メモ\" class=\"fragment\"></span><a href=\"#%E3%83%A1%E3%83%A2\"><i class=\"fa fa-link\"></i></a>メモ</h3>\n<hr>\n<p>最近のブラウザでtlsの無効/有効を設定できるけど<br><br>\nsslを無効にするやり方がみつからない。  </p>\n<p>ブラウザのバージョン下げるのもめんどうなので、CUIでやっちゃおう。</p>\n<p>wgetのヘルプをみると、、、  </p>\n<div class=\"code-frame\" data-lang=\"text\"><div class=\"highlight\"><pre>GNU Wget 1.13.4, 非対話的ネットワーク転送ソフト\n使い方: wget [オプション]... [URL]...\n<p>長いオプションで不可欠な引数は短いオプションでも不可欠です。</p>\n<p>スタートアップ:\n-V,  --version           バージョン情報を表示して終了する\n-h,  --help              このヘルプを表示する\n-b,  --background        スタート後にバックグラウンドに移行する\n-e,  --execute=COMMAND   `.wgetrc'形式のコマンドを実行する</p>\n<p>ログと入力ファイル:\n-o,  --output-file=FILE    ログを FILE に出力する\n-a,  --append-output=FILE  メッセージを FILE に追記する\n-d,  --debug               デバッグ情報を表示する\n-q,  --quiet               何も出力しない\n-v,  --verbose             冗長な出力をする (デフォルト)\n-nv, --no-verbose          冗長ではなくする\n-i,  --input-file=FILE     FILE の中に指定された URL をダウンロードする\n-F,  --force-html          入力ファイルを HTML として扱う\n-B,  --base=URL            HTML で入力されたファイル(-i -F)のリンクを\n指定した URL の相対 URL として扱う\n--config=FILE         設定ファイルを指定する</p>\n<p>ダウンロード:\n-t,  --tries=NUMBER            リトライ回数の上限を指定 (0 は無制限).\n--retry-connrefused       接続を拒否されてもリトライする\n-O,  --output-document=FILE    FILE に文書を書きこむ\n-nc, --no-clobber              存在しているファイルをダウンロードで上書きしない\n-c,  --continue                部分的にダウンロードしたファイルの続きから始める\n--progress=TYPE           進行表示ゲージの種類を TYPE に指定する\n-N,  --timestamping            ローカルにあるファイルよりも新しいファイルだけ取得する\n--no-use-server-timestamps     ローカル側のファイルのタイムスタンプに\nサーバのものを使わない\n-S,  --server-response         サーバの応答を表示する\n--spider                  何もダウンロードしない\n-T,  --timeout=SECONDS         全てのタイムアウトを SECONDS 秒に設定する\n--dns-timeout=SECS        DNS 問い合わせのタイムアウトを SECS 秒に設定する\n--connect-timeout=SECS    接続タイムアウトを SECS 秒に設定する\n--read-timeout=SECS       読み込みタイムアウトを SECS 秒に設定する\n-w,  --wait=SECONDS            ダウンロード毎に SECONDS 秒待つ\n--waitretry=SECONDS       リトライ毎に 1〜SECONDS 秒待つ\n--random-wait             ダウンロード毎に 0.5<em>WAIT〜1.5</em>WAIT 秒待つ\n--no-proxy                プロクシを使わない\n-Q,  --quota=NUMBER            ダウンロードするバイト数の上限を指定する\n--bind-address=ADDRESS    ローカルアドレスとして ADDRESS (ホスト名か IP) を使う\n--limit-rate=RATE         ダウンロード速度を RATE に制限する\n--no-dns-cache            DNS の問い合わせ結果をキャッシュしない\n--restrict-file-names=OS  OS が許しているファイル名に制限する\n--ignore-case             ファイル名/ディレクトリ名の比較で大文字小文字を無視する\n-4,  --inet4-only              IPv4 だけを使う\n-6,  --inet6-only              IPv6 だけを使う\n--prefer-family=FAMILY    指定したファミリ(IPv6, IPv4, none)で最初に接続する\n--user=USER               ftp, http のユーザ名を指定する\n--password=PASS           ftp, http のパスワードを指定する\n--ask-password            パスワードを別途入力する\n--no-iri                  IRI サポートを使わない\n--local-encoding=ENC      指定した ENC を IRI のローカルエンコーディングにする\n--remote-encoding=ENC     指定した ENC をデフォルトのリモートエンコーディングにする\n--unlink                  上書きする前にファイルを削除する</p>\n<p>ディレクトリ:\n-nd, --no-directories           ディレクトリを作らない\n-x,  --force-directories        ディレクトリを強制的に作る\n-nH, --no-host-directories      ホスト名のディレクトリを作らない\n--protocol-directories     プロトコル名のディレクトリを作る\n-P,  --directory-prefix=PREFIX  ファイルを PREFIX/ 以下に保存する\n--cut-dirs=NUMBER          リモートディレクトリ名の NUMBER 階層分を無視する</p>\n<p>HTTP オプション:\n--http-user=USER        http ユーザ名として USER を使う\n--http-password=PASS    http パスワードとして PASS を使う\n--no-cache              サーバがキャッシュしたデータを許可しない\n--default-page=NAME     デフォルトのページ名を NAME に変更します\n通常は <code class=\"language-text\">index.html&#39; です\n  -E,  --adjust-extension      HTML/CSS 文書は適切な拡張子で保存する\n       --ignore-length</code>Content-Length' ヘッダを無視する\n--header=STRING         送信するヘッダに STRING を追加する\n--max-redirect          ページで許可する最大転送回数\n--proxy-user=USER       プロクシユーザ名として USER を使う\n--proxy-password=PASS   プロクシパスワードとして PASS を使う\n--referer=URL           Referer を URL に設定する\n--save-headers          HTTP のヘッダをファイルに保存する\n-U,  --user-agent=AGENT      User-Agent として Wget/VERSION ではなく AGENT を使う\n--no-http-keep-alive    HTTP の keep-alive (持続的接続) 機能を使わない\n--no-cookies            クッキーを使わない\n--load-cookies=FILE     クッキーを FILE から読みこむ\n--save-cookies=FILE     クッキーを FILE に保存する\n--keep-session-cookies  セッションだけで用いるクッキーを保持する\n--post-data=STRING      POST メソッドを用いて STRING を送信する\n--post-file=FILE        POST メソッドを用いて FILE の中味を送信する\n--content-disposition   Content-Disposition ヘッダがあれば\nローカルのファイル名として用いる (実験的)\n--auth-no-challenge     サーバからのチャレンジを待たずに、\nBasic認証の情報を送信します。</p>\n<p>HTTPS (SSL/TLS) オプション:\n--secure-protocol=PR     セキュアプロトコルを選択する (auto, SSLv2, SSLv3, TLSv1)\n--no-check-certificate   サーバ証明書を検証しない\n--certificate=FILE       クライアント証明書として FILE を使う\n--certificate-type=TYPE  クライアント証明書の種類を TYPE (PEM, DER) に設定する\n--private-key=FILE       秘密鍵として FILE を使う\n--private-key-type=TYPE  秘密鍵の種類を TYPE (PEM, DER) に設定する\n--ca-certificate=FILE    CA 証明書として FILE を使う\n--ca-directory=DIR       CA のハッシュリストが保持されているディレクトリを指定する\n--random-file=FILE       SSL PRNG の初期化データに使うファイルを指定する\n--egd-file=FILE          EGD ソケットとして FILE を使う</p>\n<p>FTP オプション:\n--ftp-user=USER         ftp ユーザとして USER を使う\n--ftp-password=PASS     ftp パスワードとして PASS を使う\n--no-remove-listing     `.listing' ファイルを削除しない\n--no-glob               FTP ファイル名のグロブを無効にする\n--no-passive-ftp        \"passive\" 転送モードを使わない\n--retr-symlinks         再帰取得中に、シンボリックリンクでリンクされた先のファイルを取得する</p>\n<p>再帰ダウンロード:\n-r,  --recursive          再帰ダウンロードを行う\n-l,  --level=NUMBER       再帰時の階層の最大の深さを NUMBER に設定する (0 で無制限)\n--delete-after       ダウンロード終了後、ダウンロードしたファイルを削除する\n-k,  --convert-links      HTML や CSS 中のリンクをローカルを指すように変更する\n-K,  --backup-converted   リンク変換前のファイルを .orig として保存する\n-m,  --mirror             -N -r -l 0 --no-remove-listing の省略形\n-p,  --page-requisites    HTML を表示するのに必要な全ての画像等も取得する\n--strict-comments    HTML 中のコメントの処理を厳密にする</p>\n<p>再帰ダウンロード時のフィルタ:\n-A,  --accept=LIST               ダウンロードする拡張子をコンマ区切りで指定する\n-R,  --reject=LIST               ダウンロードしない拡張子をコンマ区切りで指定する\n-D,  --domains=LIST              ダウンロードするドメインをコンマ区切りで指定する\n--exclude-domains=LIST      ダウンロードしないドメインをコンマ区切りで指定する\n--follow-ftp                HTML 文書中の FTP リンクも取得対象にする\n--follow-tags=LIST          取得対象にするタグ名をコンマ区切りで指定する\n--ignore-tags=LIST          取得対象にしないタグ名をコンマ区切りで指定する\n-H,  --span-hosts                再帰中に別のホストもダウンロード対象にする\n-L,  --relative                  相対リンクだけ取得対象にする\n-I,  --include-directories=LIST  取得対象にするディレクトリを指定する\n--trust-server-names  ファイル名としてリダイレクト先のURLの最後の部分を使う\n-X,  --exclude-directories=LIST  取得対象にしないディレクトリを指定する\n-np, --no-parent                 親ディレクトリを取得対象にしない</p>\n<p>バグ報告や提案は&#x26;lt;bug-wget@gnu.org&#x26;gt;へ</p>\n</pre></div></div>\n<p>うーん、できなさそう。。。<br><br>\ngetできるか見たいだけだし、もうsslが無効のプロキシサーバを使ってみよう。  </p>\n<p><a href=\"http://www.freeproxylists.net/ja/\" rel=\"nofollow noopener\" target=\"_blank\">ここ</a>をつかって<br><br>\n<a href=\"http://sitedo3.s3.amazonaws.com/2013/09/freeproxylist.png\" rel=\"nofollow noopener\" target=\"_blank\"><img src=\"http://sitedo3.s3.amazonaws.com/2013/09/freeproxylist-300x191.png\" alt=\"freeproxylist\" width=\"300\" height=\"191\" data-canonical-src=\"http://sitedo3.s3.amazonaws.com/2013/09/freeproxylist-300x191.png\" loading=\"lazy\"></a></p>\n<div class=\"code-frame\" data-lang=\"text\"><div class=\"highlight\"><pre>wget -e 'http_proxy=[proxyサーバのアドレス]' xxx.com\n<p>スパイダーモードが有効です。リモートファイルが存在してるか確認します。\n--2013-09-26 13:33:06--  <a href=\"http://box2you.com/\">http://box2you.com/</a>\n31.170.178.2:8080 に接続しています... 接続しました。\nProxy による接続要求を送信しました、応答を待っています... 301 Moved Permanently\n場所: <a href=\"https://www.xxxxx.com/\">https://www.xxxxx.com/</a> [続く]\nスパイダーモードが有効です。リモートファイルが存在してるか確認します。\n--2013-09-26 13:33:08--  <a href=\"https://www.xxxxx.com/\">https://www.xxxxx.com/</a>\nwww.xxxxx.com (www.xxxxx.com) をDNSに問いあわせています...xxx.xxx.xxx.\nwww.xxxxx.com (www.xxxxx.com)|xxxx|:443 に接続しています... 接続しました。\nHTTP による接続要求を送信しました、応答を待っています... 200 OK\n長さ: 33221 (32K) [text/html]\nリモートファイルが存在し、さらなるリンクもあり得ますが、再帰が禁止されています -- 取得しません。</p>\n</pre></div></div>\n<p>だめじゃん。ポート443でhttpsしてんじゃん。  </p>\n<p>もはやクライアントではsslが有効なのは常識なのか、、、<br><br>\nサーバサイドだけ考えればいいのね。じゃ、この検証はスルー、、、<strong>できるかい！！</strong></p>\n<p>ここまできたら気になるわ。<br><br>\nめんどいけどhttpクライアントを使ってやろう。  </p>\n<p>下のようにrubyのgem'faraday'を使ってやりました。  </p>\n<div class=\"code-frame\" data-lang=\"text\"><div class=\"highlight\"><pre>pry(main)&gt; Faraday::Connection.new('http://box2you.com',ssl:{verify:true}).get\n=&gt; #&lt;Faraday::Response:0x00000002de94f8\n @env=\n  {:method=&gt;:get,\n   :body=&gt;\n    \"Redirecting to &lt;a href=\\\"https://www.box2you.com/\\\"&gt;https://www.box2you.com/&lt;/a&gt;\",\n   :url=&gt;#&lt;URI::HTTP:0x00000002dd90d0 URL:http://box2you.com/&gt;,\n   :request_headers=&gt;{\"User-Agent\"=&gt;\"Faraday v0.8.7\"},\n   :parallel_manager=&gt;nil,\n   :request=&gt;{:proxy=&gt;nil},\n   :ssl=&gt;{:verify=&gt;true},\n   :status=&gt;301,\n   :response_headers=&gt;\n    {\"server\"=&gt;\"nginx\",\n     \"date\"=&gt;\"Thu, 26 Sep 2013 07:05:20 GMT\",\n     \"content-type\"=&gt;\"application/x-msdownload\",\n     \"content-length\"=&gt;\"78\",\n     \"connection\"=&gt;\"close\",\n     \"location\"=&gt;\"https://www.box2you.com/\"},\n   :response=&gt;#&lt;Faraday::Response:0x00000002de94f8 ...&gt;},\n @on_complete_callbacks=[]&gt;\n</pre></div></div>\n<p>うーん？思ってたのと違うけど、できた。  </p>\n<p>どうやらRailsで全リソースをSSL対応させると、<br><br>\nhttpのみでアクセスしたときもhttpsにリダイレクトされるみたい。  </p>\n<p>これは困った。<br><br>\n下の記事を参考にアクション毎にコントロールするか。。。。  </p>\n<p><a href=\"http://o.inchiki.jp/obbr/24\" rel=\"nofollow noopener\" target=\"_blank\">RailsでSSLを利用するときのあれこれ</a></p>","frontmatter":{"date":"2014-05-07","slug":"/blog/fc131408b78fb50e8269","title":"Rails3系でのssl検証 - ブラウザのsslは無効にできない？ -","image":null,"tags":["Rails","SSL"]}}},"pageContext":{"slug":"/blog/fc131408b78fb50e8269"}},"staticQueryHashes":["1342192543"]}